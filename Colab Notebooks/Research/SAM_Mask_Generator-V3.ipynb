{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kxw5CAxnr6P6","executionInfo":{"status":"ok","timestamp":1721124816951,"user_tz":-180,"elapsed":31335,"user":{"displayName":"Haim Goldfisher","userId":"00972773137315969220"}},"outputId":"103c8253-ed34-4a38-8bbc-ba4da88b7a93"},"outputs":[{"output_type":"stream","name":"stdout","text":["  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for segment-anything (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m367.8/367.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.2/76.2 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.7/135.7 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["# Install SAM and necessary dependencies\n","!pip install -q 'git+https://github.com/facebookresearch/segment-anything.git'\n","!pip install -q jupyter_bbox_widget roboflow dataclasses-json supervision"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"PE5kymzXsBHr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721124849320,"user_tz":-180,"elapsed":32373,"user":{"displayName":"Haim Goldfisher","userId":"00972773137315969220"}},"outputId":"4ea86321-767b-401d-e194-68a2f234f1ff"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","import re\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","import supervision as sv\n","from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n","\n","torch.cuda.is_available()"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"dOY8I3vysfmk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721124870778,"user_tz":-180,"elapsed":21461,"user":{"displayName":"Haim Goldfisher","userId":"00972773137315969220"}},"outputId":"62365605-f0e7-4821-fc25-8ad529378ae5"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-07-16 10:14:09--  https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n","Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 108.157.254.15, 108.157.254.102, 108.157.254.121, ...\n","Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|108.157.254.15|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2564550879 (2.4G) [binary/octet-stream]\n","Saving to: ‘sam_vit_h_4b8939.pth’\n","\n","sam_vit_h_4b8939.pt 100%[===================>]   2.39G  99.1MB/s    in 21s     \n","\n","2024-07-16 10:14:29 (117 MB/s) - ‘sam_vit_h_4b8939.pth’ saved [2564550879/2564550879]\n","\n"]}],"source":["# CHECKPOINT downloading\n","!wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"dj-37QHlOMP_","executionInfo":{"status":"ok","timestamp":1721124887873,"user_tz":-180,"elapsed":17097,"user":{"displayName":"Haim Goldfisher","userId":"00972773137315969220"}}},"outputs":[],"source":["# Define model type and checkpoint path\n","MODEL_TYPE = \"vit_h\"\n","CHECKPOINT_PATH = \"/content/sam_vit_h_4b8939.pth\"\n","\n","# Load the model\n","sam = sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH).to(device = torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n","\n","# Init mask generator\n","mask_generator = SamAutomaticMaskGenerator(sam)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"v4uNqZllT4Dc","executionInfo":{"status":"ok","timestamp":1721124887874,"user_tz":-180,"elapsed":4,"user":{"displayName":"Haim Goldfisher","userId":"00972773137315969220"}}},"outputs":[],"source":["# # https://www.freecodecamp.org/news/use-segment-anything-model-to-create-masks/\n","\n","# # Give the path of your image\n","# IMAGE_PATH= '/content/drive/MyDrive/KernelGAN-Masks/imgs/img1/img1_lr.png'\n","# # Read the image from the path\n","# image= cv2.imread(IMAGE_PATH)\n","# # Convert to RGB format\n","# image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","\n","# # Generate segmentation mask\n","# output_mask = mask_generator.generate(image_rgb)\n","# # print(output_mask)\n","\n","# # Function that inputs the output and plots image and mask\n","# def create_masks(result_dict, axes=None, masks_num=None):\n","#     if axes:\n","#       ax = axes\n","#     else:\n","#       ax = plt.gca()\n","#       ax.set_autoscale_on(False)\n","#     if not masks_num:\n","#       masks_num = len(result_dict)\n","#     sorted_result = sorted(result_dict, key=lambda x: x['area'], reverse=True)\n","#     sorted_result = sorted_result[:masks_num]\n","#     # Plot for each segment area\n","#     for val in sorted_result:\n","#       mask = val['segmentation']\n","#       img = np.ones((mask.shape[0], mask.shape[1], 3))\n","#       color_mask = np.random.random((1, 3)).tolist()[0]\n","#       for i in range(3):\n","#           img[:,:,i] = color_mask[i]\n","#           ax.imshow(np.dstack((img, mask*0.5)))\n","#     return sorted_result\n","\n","\n","# _,axes = plt.subplots(1,2, figsize=(16,16))\n","# axes[0].imshow(image_rgb)\n","# masks = create_masks(output_mask, axes[1],2)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"ahsOhMz4btw3","executionInfo":{"status":"ok","timestamp":1721124887874,"user_tz":-180,"elapsed":3,"user":{"displayName":"Haim Goldfisher","userId":"00972773137315969220"}}},"outputs":[],"source":["# import cv2\n","# import numpy as np\n","# import matplotlib.pyplot as plt\n","\n","# def extract_largest_component(mask):\n","#     # Convert boolean array to a binary image (0 and 255)\n","#     true_map_binary = (mask * 255).astype(np.uint8)\n","\n","#     # Apply morphological operations to remove small noise\n","#     kernel = np.ones((10, 10), np.uint8)\n","#     true_map_binary = cv2.morphologyEx(true_map_binary, cv2.MORPH_CLOSE, kernel)\n","\n","#     # Use connectedComponentsWithStats to find all connected components\n","#     num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(true_map_binary)\n","\n","#     # The first component is the background, so we start with the second one\n","#     largest_component = 1 + np.argmax(stats[1:, cv2.CC_STAT_AREA])\n","\n","#     # Create a new mask for the largest component\n","#     largest_component_mask = (labels == largest_component).astype(np.uint8) * 255\n","\n","#     return largest_component_mask\n","\n","# # Example usage:\n","# masl = masks[0]['segmentation']  # Replace with your actual mask\n","# largest_component_mask = extract_largest_component(masl)\n","\n","# # Display the new clean mask and its negative with boundaries\n","# plt.figure(figsize=(12, 6))\n","\n","# # Plot for largest component mask\n","# plt.subplot(1, 2, 1)\n","# plt.imshow(largest_component_mask, cmap='gray')\n","# plt.title('Largest Component Mask')\n","# plt.gca().set_xticks([])\n","# plt.gca().set_yticks([])\n","# plt.gca().spines['top'].set_linewidth(2)\n","# plt.gca().spines['bottom'].set_linewidth(2)\n","# plt.gca().spines['left'].set_linewidth(2)\n","# plt.gca().spines['right'].set_linewidth(2)\n","\n","# # Plot for negative of largest component mask\n","# plt.subplot(1, 2, 2)\n","# plt.imshow(255 - largest_component_mask, cmap='gray')\n","# plt.title('Negative of Largest Component Mask')\n","# plt.gca().set_xticks([])\n","# plt.gca().set_yticks([])\n","# plt.gca().spines['top'].set_linewidth(2)\n","# plt.gca().spines['bottom'].set_linewidth(2)\n","# plt.gca().spines['left'].set_linewidth(2)\n","# plt.gca().spines['right'].set_linewidth(2)\n","\n","# plt.tight_layout()\n","# plt.show()\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"gxwc7WjyRDX0","colab":{"base_uri":"https://localhost:8080/","height":703},"executionInfo":{"status":"ok","timestamp":1721124926288,"user_tz":-180,"elapsed":38417,"user":{"displayName":"Haim Goldfisher","userId":"00972773137315969220"}},"outputId":"52fe75eb-8036-423d-cb25-88dbce438f4c"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/KernelGAN-Masks/imgs/img1\n","/content/drive/MyDrive/KernelGAN-Masks/masks/img1/back_hr_mask.png\n","/content/drive/MyDrive/KernelGAN-Masks/masks/img1/back_lr_mask.png\n","/content/drive/MyDrive/KernelGAN-Masks/masks/img1/obj_hr_mask.png\n","/content/drive/MyDrive/KernelGAN-Masks/masks/img1/obj_lr_mask.png\n","/content/drive/MyDrive/KernelGAN-Masks/imgs/img2\n","/content/drive/MyDrive/KernelGAN-Masks/masks/img2/back_hr_mask.png\n","/content/drive/MyDrive/KernelGAN-Masks/masks/img2/back_lr_mask.png\n","/content/drive/MyDrive/KernelGAN-Masks/masks/img2/obj_hr_mask.png\n","/content/drive/MyDrive/KernelGAN-Masks/masks/img2/obj_lr_mask.png\n","/content/drive/MyDrive/KernelGAN-Masks/imgs/img3\n","/content/drive/MyDrive/KernelGAN-Masks/masks/img3/back_hr_mask.png\n","/content/drive/MyDrive/KernelGAN-Masks/masks/img3/back_lr_mask.png\n","/content/drive/MyDrive/KernelGAN-Masks/masks/img3/obj_hr_mask.png\n","/content/drive/MyDrive/KernelGAN-Masks/masks/img3/obj_lr_mask.png\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["# @title קוד הרלוונטי\n","\n","def create_blocky_mask(img):\n","   scale_factor = 0.2\n","   small_lr_back = cv2.resize(img, (0, 0), fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_NEAREST)\n","   blocky_lr_back = cv2.resize(small_lr_back, lr_back.shape[::-1], interpolation=cv2.INTER_NEAREST)\n","   return blocky_lr_back\n","\n","\n","# Assuming mask_generator is an instance of some class capable of generating masks\n","def extract_numbers_from_filename(filename):\n","    # Use regular expression to find numbers in the filename\n","    match = re.search(r'\\d+', filename)\n","\n","    # If numbers are found, convert them to an integer\n","    if match:\n","        return int(match.group())\n","    else:\n","        return None\n","\n","def create_masks(result_dict, axes=None, masks_num=None):\n","    if axes:\n","      ax = axes\n","    else:\n","      ax = plt.gca()\n","      ax.set_autoscale_on(False)\n","    if not masks_num:\n","      masks_num = len(result_dict)\n","    sorted_result = sorted(result_dict, key=lambda x: x['area'], reverse=True)\n","    sorted_result = sorted_result[:masks_num]\n","    return sorted_result\n","\n","\n","def extract_largest_component(mask):\n","    # Convert boolean array to a binary image (0 and 255)\n","    true_map_binary = (mask * 255).astype(np.uint8)\n","\n","    # Apply morphological operations to remove small noise\n","    kernel = np.ones((10, 10), np.uint8)\n","    true_map_binary = cv2.morphologyEx(true_map_binary, cv2.MORPH_CLOSE, kernel)\n","\n","    # Use connectedComponentsWithStats to find all connected components\n","    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(true_map_binary)\n","\n","    # The first component is the background, so we start with the second one\n","    largest_component = 1 + np.argmax(stats[1:, cv2.CC_STAT_AREA])\n","\n","    # Create a new mask for the largest component\n","    largest_component_mask = (labels == largest_component).astype(np.uint8) * 255\n","\n","    return largest_component_mask\n","\n","def create_mask(image_path):\n","    image_rgb = cv2.imread(image_path)\n","\n","      # Generate segmentation mask\n","    output_mask = mask_generator.generate(image_rgb)\n","\n","            # Create a mask for the largest component\n","    masks = create_masks(output_mask)\n","    mask = masks[0]['segmentation']\n","    largest_component_mask = extract_largest_component(mask)\n","    return largest_component_mask\n","\n","# do the code aobve for all the imgs in the src folder\n","base = \"/content/drive/MyDrive/KernelGAN-Masks\"\n","src = base + \"/imgs\"\n","dst = base + \"/masks\"\n","\n","files = os.listdir(src)\n","\n","for file_name in files:\n","    image_path = os.path.join(src, file_name)\n","    img_num = extract_numbers_from_filename(file_name)\n","    dir_path = os.path.join(dst, 'img' + str(img_num))\n","    if not os.path.exists(dir_path):\n","        os.mkdir(dir_path)\n","    print(image_path)\n","\n","    for img in os.listdir(image_path):\n","        if \"lr\" in img:\n","            image_path_lr = os.path.join(image_path, img)\n","            break\n","\n","    lr_back = create_mask(image_path_lr)\n","    new_path_back_hr = os.path.join(dir_path, \"back_hr_mask.png\")\n","    new_path_back_lr = os.path.join(dir_path, \"back_lr_mask.png\")\n","    new_path_obj_hr = os.path.join(dir_path, \"obj_hr_mask.png\")\n","    new_path_obj_lr = os.path.join(dir_path, \"obj_lr_mask.png\")\n","\n","    hr_back = cv2.resize(lr_back, dsize=(lr_back.shape[1]*2, lr_back.shape[0]*2), interpolation=cv2.INTER_NEAREST)\n","    hr_obj = cv2.bitwise_not(hr_back)\n","    lr_obj = cv2.bitwise_not(lr_back)\n","\n","    cv2.imwrite(new_path_back_hr,create_blocky_mask(hr_back))\n","    cv2.imwrite(new_path_back_lr, create_blocky_mask(lr_back))\n","    cv2.imwrite(new_path_obj_hr, create_blocky_mask(hr_obj))\n","    cv2.imwrite(new_path_obj_lr, create_blocky_mask(lr_obj))\n","\n","    print(new_path_back_hr)\n","    print(new_path_back_lr)\n","    print(new_path_obj_hr)\n","    print(new_path_obj_lr)\n"]},{"cell_type":"markdown","metadata":{"id":"mRY0jnLkimmG"},"source":[]},{"cell_type":"code","execution_count":8,"metadata":{"id":"39di7XN71zpe","executionInfo":{"status":"ok","timestamp":1721124926289,"user_tz":-180,"elapsed":8,"user":{"displayName":"Haim Goldfisher","userId":"00972773137315969220"}}},"outputs":[],"source":["# # prompt: put theblockymask on the real imge\n","\n","# import matplotlib.pyplot as plt\n","# def apply_blocky_mask(image_path, mask_path):\n","#   \"\"\"\n","#   Applies a blocky mask to an image.\n","\n","#   Args:\n","#     image_path: Path to the input image.\n","#     mask_path: Path to the blocky mask.\n","\n","#   Returns:\n","#     The image with the blocky mask applied.\n","#   \"\"\"\n","\n","#   # Load the image and mask\n","#   image = cv2.imread(image_path)\n","#   mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n","\n","#   # Apply the mask to the image\n","#   masked_image = cv2.bitwise_and(image, image, mask=mask)\n","\n","#   return masked_image\n","\n","# # Example usage:\n","# image_path = '/content/drive/MyDrive/KernelGAN-Masks/imgs/img5/img5_lr.png'\n","# mask_path = '/content/drive/MyDrive/KernelGAN-Masks/masks/img5/blocky_lr_obj_mask.png'\n","# masked_image = apply_blocky_mask(image_path, mask_path)\n","\n","# # Display the masked image\n","# plt.imshow(masked_image)\n","# plt.show()\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"5_Rase3grj_O","executionInfo":{"status":"ok","timestamp":1721124926289,"user_tz":-180,"elapsed":6,"user":{"displayName":"Haim Goldfisher","userId":"00972773137315969220"}}},"outputs":[],"source":["# # Function to extract numbers from filename\n","# def extract_numbers_from_filename(filename):\n","#     # Use regular expression to find numbers in the filename\n","#     match = re.search(r'\\d+', filename)\n","\n","#     # If numbers are found, convert them to an integer\n","#     if match:\n","#         return int(match.group())\n","#     else:\n","#         return None\n","\n","# # Main processing pipeline\n","# def process_images(base_dir):\n","#     src = os.path.join(base_dir, \"imgs\")\n","#     dst = os.path.join(base_dir, \"masks\")\n","\n","#     files = os.listdir(src)\n","\n","#     for file_name in files:\n","#         image_path = os.path.join(src, file_name)\n","#         img_num = extract_numbers_from_filename(file_name)\n","#         if img_num is None:\n","#             continue\n","\n","#         dir_path = os.path.join(dst, 'img' + str(img_num))\n","#         if not os.path.exists(dir_path):\n","#             os.mkdir(dir_path)\n","\n","#         print(image_path)\n","#         for img in os.listdir(image_path):\n","#             if \"lr\" in img:\n","#                 image_path_lr = os.path.join(image_path, img)\n","#                 break\n","\n","#         # Load image\n","#         img = cv2.imread(image_path_lr)\n","#         image_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","\n","#         # Generate masks with SAM\n","#         sam_result = mask_generator.generate(image_rgb)\n","\n","#         # Process SAM results (example: extracting masks)\n","#         masks = [result['segmentation'] for result in sam_result]\n","\n","#         # Save masks (example: saving one of the masks)\n","#         combined_mask = np.zeros_like(img[:, :, 0])\n","#         for mask in masks:\n","#             combined_mask += mask.astype(np.uint8) * 255\n","\n","#         # Apply smoothing (optional)\n","#         # combined_mask = cv2.GaussianBlur(combined_mask, (5, 5), 0)\n","\n","#         # Display original image and SAM mask\n","#         plt.figure(figsize=(10, 5))\n","#         plt.subplot(1, 2, 1)\n","#         plt.title('Original Image')\n","#         plt.imshow(img[:, :, ::-1])  # Convert BGR to RGB for display\n","#         plt.subplot(1, 2, 2)\n","#         plt.title('SAM Mask')\n","#         plt.imshow(combined_mask, cmap='gray')\n","#         plt.show()\n","\n","#         # Save processed masks (example: saving HR and LR masks)\n","#         new_path_back_hr = os.path.join(dir_path, \"back_hr_mask.png\")\n","#         new_path_back_lr = os.path.join(dir_path, \"back_lr_mask.png\")\n","#         new_path_obj_hr = os.path.join(dir_path, \"obj_hr_mask.png\")\n","#         new_path_obj_lr = os.path.join(dir_path, \"obj_lr_mask.png\")\n","\n","#         hr_back = cv2.resize(combined_mask, dsize=[combined_mask.shape[1]*2, combined_mask.shape[0]*2], interpolation=cv2.INTER_CUBIC)\n","#         hr_obj = cv2.bitwise_not(hr_back)\n","#         lr_obj = cv2.bitwise_not(combined_mask)\n","\n","#         cv2.imwrite(new_path_back_hr, hr_back)\n","#         cv2.imwrite(new_path_back_lr, combined_mask)\n","#         cv2.imwrite(new_path_obj_hr, hr_obj)\n","#         cv2.imwrite(new_path_obj_lr, lr_obj)\n","\n","#         print(new_path_back_hr)\n","#         print(new_path_back_lr)\n","#         print(new_path_obj_hr)\n","#         print(new_path_obj_lr)\n","\n","#         plt.imshow(hr_obj)\n","#         plt.show()\n","#         plt.imshow(hr_back)\n","#         plt.show()\n","\n","# # Example usage\n","# base_dir = \"/content/drive/MyDrive/KernelGAN-Masks\"\n","# process_images(base_dir)\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"d-K5IKC-GsCN","executionInfo":{"status":"ok","timestamp":1721124926289,"user_tz":-180,"elapsed":6,"user":{"displayName":"Haim Goldfisher","userId":"00972773137315969220"}}},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1V-CxbKXHDigj3ixsDfHIIdDtaVaRfO-H","timestamp":1721116965701}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}